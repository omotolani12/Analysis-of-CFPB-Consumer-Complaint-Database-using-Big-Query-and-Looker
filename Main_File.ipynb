{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omotolani12/Analysis-of-CFPB-Consumer-Complaint-Database-using-Big-Query-and-Looker/blob/main/Main_File.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNTmMJIMYjiC"
      },
      "outputs": [],
      "source": [
        "#Install neccessary libraries to use llama\n",
        "!pip install transformers torch accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFjx3o4HU_83"
      },
      "outputs": [],
      "source": [
        "#Installation of Gradio for building the frontend solution\n",
        "!pip install --upgrade gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6AfgF3_arYL",
        "outputId": "e2d24845-02a1-439c-a5ec-c116d75c803a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: read).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lD_oW1uavGp",
        "outputId": "d96bc2cd-935d-48fa-876c-71d2337f3762"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Omotola12\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli whoami"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsBrtGpZYmcQ",
        "outputId": "58ce6fec-582a-4f5f-f2e9-11606b2e611c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:769: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from transformers import AutoTokenizer\n",
        "import gradio as gr\n",
        "import transformers\n",
        "import torch\n",
        "\n",
        "# Define the model name or path\n",
        "model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "\n",
        "# Load the tokenizer for the specified model using the AutoTokenizer class\n",
        "# The 'use_auth_token=True' parameter indicates that an authentication token is required to access the model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model, use_auth_token=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1437d29789994a99b8efc216553bff1a",
            "13db0513c39d4799b26cbaa531f2e057",
            "10e166d3490c4eb18a1055129fc72f0e",
            "085f0c8ff2b94122b16d95ef6c064dfc",
            "ca100e6fccb04b5f8a206d61c7fa4400",
            "66ad904ca7104340a496b2e3af705d48",
            "de47ee8b6c474d219730e3f4413bd4a3",
            "d6f7c374b2714f2a87e537868bc9db6b",
            "9963262bc8a74c9687234db0f6480671",
            "e73464375ce247629845cc068aa5995c",
            "93eec762ed98420cb2efdd71f559b895"
          ]
        },
        "id": "0AqJo1R_a9IM",
        "outputId": "fc0fb41d-1216-4143-ad0f-c07c3207b7cc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1437d29789994a99b8efc216553bff1a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "## Create a pipeline for text generation using the specified model\n",
        "# torch_dtype=torch.float16 specifies the use of float16 precision for computations\n",
        "# device_map=\"auto\" allows automatic device allocation for computation (e.g., GPU if available)\n",
        "\n",
        "from transformers import pipeline\n",
        "llama_pipeline = pipeline(\n",
        "    \"text-generation\",  # LLM task\n",
        "    model=model,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a system prompt for the chatbot that sets the tone for the responses\n",
        "SYSTEM_PROMPT = \"\"\"<s>[INST] <<SYS>>\n",
        "You are a helpful bot. Your answers are clear and concise.\n",
        "<</SYS>>\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def format_message(message: str, history: list, memory_limit: int = 3) -> str:\n",
        "    if len(history) > memory_limit:\n",
        "        history = history[-memory_limit:]\n",
        "\n",
        "    if len(history) == 0:\n",
        "        return SYSTEM_PROMPT + f\"{message} [/INST]\"\n",
        "\n",
        "    formatted_message = SYSTEM_PROMPT + f\"{history[0][0]} [/INST] {history[0][1]} </s>\"\n",
        "\n",
        "    for user_msg, model_answer in history[1:]:\n",
        "        formatted_message += f\"<s>[INST] {user_msg} [/INST] {model_answer} </s>\"\n",
        "\n",
        "    formatted_message += f\"<s>[INST] {message} [/INST]\"\n",
        "\n",
        "    return formatted_message"
      ],
      "metadata": {
        "id": "i3zEymssQb0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Generate a response using the llama_pipeline\n",
        "def get_llama_response(message: str, history: list) -> str:\n",
        "    query = format_message(message, history)\n",
        "    sequences = llama_pipeline(\n",
        "        query,\n",
        "        do_sample=True,\n",
        "        top_k=10,\n",
        "        num_return_sequences=1,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        max_length=1024,\n",
        "    )\n",
        "\n",
        "    generated_text = sequences[0]['generated_text']\n",
        "    response = generated_text[len(query):]  # Remove the prompt from the output\n",
        "\n",
        "# Return the response, stripped of any leading or trailing whitespace\n",
        "    return response.strip()"
      ],
      "metadata": {
        "id": "Nl-e7k6eQeb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate the fashion recommendation prompt\n",
        "def generate_recommendation(style, occasions, monday_outfit, colors, clothing_important, night_out_style, brunch_style,\n",
        "                            preferred_styles, typical_purchases, non_negotiable, open_suggestions, scale_sizes,\n",
        "                            expressive_dressing, disliked_clothes, loyal_brands, budget):\n",
        "    #Create prompt for Llama Model. Here we have passed in a prompt message and also added the user inputs as part of the prompt\n",
        "    prompt = (f\"You are a fashion stylist. Based on the body build, height, and preferred style, please provide detailed fashion recommendations. \"\n",
        "              \"Include suggestions for types of clothing, styles, and accessories that would be flattering. Provide examples and tips for creating \"\n",
        "              \"a stylish and balanced look. Please provide specific brands for the recommended types of clothes, styles, and accessories and also \"\n",
        "              f\"give advice on price range. Here are the details:\\n\"\n",
        "              f\"Overall Style: {style}\\n\"\n",
        "              f\"Occasions: {occasions}\\n\"\n",
        "              f\"Monday Outfit: {monday_outfit}\\n\"\n",
        "              f\"Preferred Colors: {colors}\\n\"\n",
        "              f\"Important Clothing Features: {clothing_important}\\n\"\n",
        "              f\"Night Out Style: {night_out_style}\\n\"\n",
        "              f\"Brunch Style: {brunch_style}\\n\"\n",
        "              f\"Preferred Styles: {preferred_styles}\\n\"\n",
        "              f\"Typical Purchases: {typical_purchases}\\n\"\n",
        "              f\"Non-negotiable in Clothing: {non_negotiable}\\n\"\n",
        "              f\"Open to Suggestions: {open_suggestions}\\n\"\n",
        "              f\"Scale Sizes: {scale_sizes}\\n\"\n",
        "              f\"Expressive in Dressing: {expressive_dressing}\\n\"\n",
        "              f\"Disliked Clothes: {disliked_clothes}\\n\"\n",
        "              f\"Loyal Brands: {loyal_brands}\\n\"\n",
        "              f\"Typical Budget: {budget}\\n\"\n",
        "              \"Provide specific outfit suggestions including the types of clothing, styles, and accessories that fit these preferences. \"\n",
        "              \"Mention specific brands that align with the style and budget. Also, offer advice on how to mix and match pieces for different occasions.\")\n",
        "\n",
        "    # Get response from Llama model\n",
        "    history = []\n",
        "    response = get_llama_response(prompt, history)\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "q_cPW74FQjFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "b6-b6VnTL7on",
        "outputId": "fa8301bb-c1b0-4cf2-a175-255955c850bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://9071c0e306542a1415.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9071c0e306542a1415.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Define the Gradio interface inputs\n",
        "inputs = [\n",
        "    gr.Textbox(label=\"What describes your overall style the best?\"),\n",
        "    gr.Textbox(label=\"What occasions do you typically dress for?\"),\n",
        "    gr.Textbox(label=\"What does your Monday outfit look like?\"),\n",
        "    gr.Textbox(label=\"Are there specific tones/colors you like?\"),\n",
        "    gr.Textbox(label=\"What are some things about clothing that are important to you?\"),\n",
        "    gr.Textbox(label=\"How would you describe your style for a night out?\"),\n",
        "    gr.Textbox(label=\"How would you describe your style for a brunch?\"),\n",
        "    gr.Textbox(label=\"Do you prefer classy, timeless, trendy or fashion forward styles?\"),\n",
        "    gr.Textbox(label=\"What do you typically buy when buying clothes? (blouse, trouser, shoes)\"),\n",
        "    gr.Textbox(label=\"What is a non-negotiable in your dresses?\"),\n",
        "    gr.Textbox(label=\"How open are you to wide suggestions from us?\"),\n",
        "    gr.Textbox(label=\"Please provide your scale sizes (boobs, waist, height, and so on).\"),\n",
        "    gr.Textbox(label=\"Are you expressive in your dressing?\"),\n",
        "    gr.Textbox(label=\"Are there clothes you dislike?\"),\n",
        "    gr.Textbox(label=\"Are there brands you are loyal to?\"),\n",
        "    gr.Textbox(label=\"What is your typical budget for clothing items?\")\n",
        "]\n",
        "\n",
        "# Define the Gradio interface outputs\n",
        "outputs = gr.Textbox(label=\"Fashion Recommendation\")\n",
        "\n",
        "# Create and launch the Gradio interface\n",
        "gr.Interface(fn=generate_recommendation, inputs=inputs, outputs=outputs, title=\"Fashion Stylist\", description=\"Get personalized fashion recommendations based on your preferences.\").launch()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1437d29789994a99b8efc216553bff1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13db0513c39d4799b26cbaa531f2e057",
              "IPY_MODEL_10e166d3490c4eb18a1055129fc72f0e",
              "IPY_MODEL_085f0c8ff2b94122b16d95ef6c064dfc"
            ],
            "layout": "IPY_MODEL_ca100e6fccb04b5f8a206d61c7fa4400"
          }
        },
        "13db0513c39d4799b26cbaa531f2e057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66ad904ca7104340a496b2e3af705d48",
            "placeholder": "​",
            "style": "IPY_MODEL_de47ee8b6c474d219730e3f4413bd4a3",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "10e166d3490c4eb18a1055129fc72f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6f7c374b2714f2a87e537868bc9db6b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9963262bc8a74c9687234db0f6480671",
            "value": 2
          }
        },
        "085f0c8ff2b94122b16d95ef6c064dfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e73464375ce247629845cc068aa5995c",
            "placeholder": "​",
            "style": "IPY_MODEL_93eec762ed98420cb2efdd71f559b895",
            "value": " 2/2 [01:03&lt;00:00, 29.03s/it]"
          }
        },
        "ca100e6fccb04b5f8a206d61c7fa4400": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66ad904ca7104340a496b2e3af705d48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de47ee8b6c474d219730e3f4413bd4a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6f7c374b2714f2a87e537868bc9db6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9963262bc8a74c9687234db0f6480671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e73464375ce247629845cc068aa5995c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93eec762ed98420cb2efdd71f559b895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}